{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Mini Vision Transformer (ViT) on CIFAR-10\n",
    "### End-to-End Training & Inference Pipeline\n",
    "\n",
    "Welcome to this self-contained Mini-ViT demo! This notebook is designed to train a Vision Transformer from scratch on your local machine, respecting your hardware constraints.\n",
    "\n",
    "**Key Features:**\n",
    "*   **Automatic Resource Management**: Automatically falls back to smaller models or batch sizes if CUDA OOM occurs.\n",
    "*   **Time Budgeting**: Ensures training fits within your specified time limit (default: 30 mins) by adjusting epochs dynamically.\n",
    "*   **Interactive Inference**: Test the model with your own images!\n",
    "\n",
    "---\n",
    "**Instructions:**\n",
    "1.  Run all cells in order.\n",
    "2.  Watch the **Training Loop** section for live progress.\n",
    "3.  Use the final cells to save your model and run predictions on your own images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & Imports\n",
    "We start by importing PyTorch and setting a global random seed for reproducibility. We also detect if a GPU is available.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ PyTorch Version: 2.7.1+cu118\n",
      "üîß Device: cuda\n",
      "   GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        \n",
    "set_seed(42)\n",
    "\n",
    "print(f\"üì¶ PyTorch Version: {torch.__version__}\")\n",
    "print(f\"üîß Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dynamic Configuration\n",
    "This class handles the training configuration. It includes a smart `downgrade()` method that automatically reduces the batch size, model dimension, or network depth if an Out-Of-Memory (OOM) error causes a crash.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, mode='full', time_budget_min=30, force_cpu=False):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() and not force_cpu else 'cpu'\n",
    "        self.image_size = 32  # CIFAR-10 default\n",
    "        self.patch_size = 4   # 32/4 = 8x8 patches\n",
    "        self.num_classes = 10\n",
    "        \n",
    "        # Primary Config (Target)\n",
    "        self.dim = 128\n",
    "        self.depth = 4\n",
    "        self.heads = 4\n",
    "        self.mlp_dim = 256\n",
    "        self.batch_size = 64\n",
    "        \n",
    "        # Training Settings\n",
    "        self.epochs = 10 if mode == 'demo' else 50\n",
    "        self.lr = 1e-3\n",
    "        self.weight_decay = 0.05\n",
    "        \n",
    "        self.time_budget = time_budget_min * 60  # seconds\n",
    "        self.fallback_level = 0\n",
    "        \n",
    "    def downgrade(self):\n",
    "        \"\"\"Attempts to reduce resource usage. Returns True if downgraded, False if min limit reached.\"\"\"\n",
    "        self.fallback_level += 1\n",
    "        \n",
    "        # Level 1: Reduce Batch Size\n",
    "        if self.batch_size > 16:\n",
    "            print(f\"‚ö†Ô∏è [Fallback] Reducing batch size from {self.batch_size} to {self.batch_size // 2}\")\n",
    "            self.batch_size //= 2\n",
    "            return True\n",
    "        \n",
    "        # Level 2: Reduce Model Dim\n",
    "        if self.dim == 128:\n",
    "            print(f\"‚ö†Ô∏è [Fallback] Reducing model dim from 128 to 64\")\n",
    "            self.dim = 64\n",
    "            self.mlp_dim = 128\n",
    "            self.batch_size = 64 # Reset batch size to try again\n",
    "            return True\n",
    "            \n",
    "        # Level 3: Reduce Depth\n",
    "        if self.depth == 4:\n",
    "            print(f\"‚ö†Ô∏è [Fallback] Reducing depth from 4 to 2\")\n",
    "            self.depth = 2\n",
    "            self.batch_size = 64 # Reset batch size\n",
    "            return True\n",
    "            \n",
    "        return False\n",
    "\n",
    "    def __str__(self):\n",
    "        return (f\"Img:{self.image_size}, Patch:{self.patch_size}, Dim:{self.dim}, \"\n",
    "                f\"Depth:{self.depth}, Heads:{self.heads}, Batch:{self.batch_size}, Epochs:{self.epochs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mini-ViT Architecture\n",
    "We implement the Vision Transformer from scratch.\n",
    "*   **PatchEmbedding**: Breaks the image into flattened patches and projects them.\n",
    "*   **TransformerBlock**: The core unit with Multi-Head Attention and an MLP.\n",
    "*   **MiniViT**: The main class combining embeddings, position tokens, blocks, and the classification head.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, image_size, patch_size, dim, channels=3):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(channels, dim, kernel_size=patch_size, stride=patch_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.proj(x) # (B, D, H/P, W/P)\n",
    "        x = x.flatten(2).transpose(1, 2) # (B, N, D)\n",
    "        return x\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, heads, mlp_dim):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = nn.MultiheadAttention(dim, heads, batch_first=True)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.mlp = MLP(dim, mlp_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_norm = self.norm1(x)\n",
    "        attn_out, _ = self.attn(x_norm, x_norm, x_norm)\n",
    "        x = x + attn_out\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "class MiniViT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.patch_embed = PatchEmbedding(config.image_size, config.patch_size, config.dim)\n",
    "        num_patches = (config.image_size // config.patch_size) ** 2\n",
    "        \n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, config.dim))\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, num_patches + 1, config.dim))\n",
    "        \n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(config.dim, config.heads, config.mlp_dim)\n",
    "            for _ in range(config.depth)\n",
    "        ])\n",
    "        \n",
    "        self.norm = nn.LayerNorm(config.dim)\n",
    "        self.head = nn.Linear(config.dim, config.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.pos_embed\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.norm(x)\n",
    "        return self.head(x[:, 0])\n",
    "\n",
    "    def count_params(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation (CIFAR-10)\n",
    "We use `torchvision` to download and load CIFAR-10.\n",
    "*   If you placed the `cifar-10-python.tar.gz` in `./data`, it will find and extract it.\n",
    "*   If the file is missing and no internet is available, it falls back to **synthetic noise** (for testing the code).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(config, subsample=False):\n",
    "    print(f\"üì• Loading Data... (Subsample={subsample})\")\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "        testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to download CIFAR10: {e}. Using synthetic data.\")\n",
    "        trainset = torchvision.datasets.FakeData(size=20000 if subsample else 50000, image_size=(3, 32, 32), num_classes=10, transform=transforms.ToTensor())\n",
    "        testset = torchvision.datasets.FakeData(size=10000, image_size=(3, 32, 32), num_classes=10, transform=transforms.ToTensor())\n",
    "\n",
    "    if subsample and len(trainset) > 20000:\n",
    "        indices = list(range(20000))\n",
    "        trainset = torch.utils.data.Subset(trainset, indices)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=config.batch_size, shuffle=True, num_workers=2, pin_memory=(config.device=='cuda'))\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n",
    "    return trainloader, testloader, trainset, testset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Utilities\n",
    "Define `train_one_epoch` (with Mixed Precision support) and `evaluate`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for inputs, targets in loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast(enabled=(device == 'cuda')):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "        if device == 'cuda':\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    return total_loss / len(loader), 100. * correct / total\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    return 100. * correct / total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Main Execution Loop\n",
    "This runs the full pipeline:\n",
    "1.  **Config & OOM Check**: Re-initializes model if memory error occurs.\n",
    "2.  **Warmup**: Checks speed.\n",
    "3.  **Training**: Runs epochs.\n",
    "4.  **Auto-Save**: Saves `model_final.pt` automatically.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Main Loop with Budget: 30 mins\n",
      "\n",
      "----------------------------------------------------------------\n",
      "‚ñ∂Ô∏è Attempting Config: Img:32, Patch:4, Dim:128, Depth:4, Heads:4, Batch:64, Epochs:50\n",
      "----------------------------------------------------------------\n",
      "üì• Loading Data... (Subsample=False)\n",
      "üß† Model Parameters: 546,186\n",
      "\n",
      "üî• Running warmup epoch to measure speed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sabyasachi Samanta\\AppData\\Local\\Temp\\ipykernel_27096\\1062207180.py:29: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(config.device == 'cuda'))\n",
      "C:\\Users\\Sabyasachi Samanta\\AppData\\Local\\Temp\\ipykernel_27096\\952415684.py:7: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device == 'cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Warmup done in 22.85s.\n",
      "\n",
      "üèãÔ∏è Starting training for 50 epochs...\n",
      "Epoch 01/50 | ‚è±Ô∏è  47.5s | üìâ Loss: 1.4583 | ‚úÖ Train:  47.1% | ‚≠ê Val:  50.2%\n",
      "Epoch 02/50 | ‚è±Ô∏è  56.8s | üìâ Loss: 1.3470 | ‚úÖ Train:  51.0% | ‚≠ê Val:  53.4%\n",
      "Epoch 03/50 | ‚è±Ô∏è  48.3s | üìâ Loss: 1.2610 | ‚úÖ Train:  54.2% | ‚≠ê Val:  57.0%\n",
      "Epoch 04/50 | ‚è±Ô∏è  42.7s | üìâ Loss: 1.1973 | ‚úÖ Train:  56.8% | ‚≠ê Val:  58.4%\n",
      "Epoch 05/50 | ‚è±Ô∏è  48.4s | üìâ Loss: 1.1285 | ‚úÖ Train:  59.6% | ‚≠ê Val:  61.1%\n",
      "Epoch 06/50 | ‚è±Ô∏è  50.2s | üìâ Loss: 1.0687 | ‚úÖ Train:  61.8% | ‚≠ê Val:  63.0%\n",
      "Epoch 07/50 | ‚è±Ô∏è  58.1s | üìâ Loss: 1.0274 | ‚úÖ Train:  63.2% | ‚≠ê Val:  64.1%\n",
      "Epoch 08/50 | ‚è±Ô∏è  57.5s | üìâ Loss: 0.9789 | ‚úÖ Train:  65.1% | ‚≠ê Val:  64.9%\n",
      "Epoch 09/50 | ‚è±Ô∏è  50.9s | üìâ Loss: 0.9417 | ‚úÖ Train:  66.4% | ‚≠ê Val:  68.2%\n",
      "Epoch 10/50 | ‚è±Ô∏è  30.8s | üìâ Loss: 0.9096 | ‚úÖ Train:  67.7% | ‚≠ê Val:  67.9%\n",
      "Epoch 11/50 | ‚è±Ô∏è  46.1s | üìâ Loss: 0.8748 | ‚úÖ Train:  68.7% | ‚≠ê Val:  68.2%\n",
      "Epoch 12/50 | ‚è±Ô∏è  48.3s | üìâ Loss: 0.8449 | ‚úÖ Train:  69.9% | ‚≠ê Val:  70.0%\n",
      "Epoch 13/50 | ‚è±Ô∏è  52.1s | üìâ Loss: 0.8119 | ‚úÖ Train:  71.2% | ‚≠ê Val:  70.4%\n",
      "Epoch 14/50 | ‚è±Ô∏è  52.7s | üìâ Loss: 0.7920 | ‚úÖ Train:  71.7% | ‚≠ê Val:  72.9%\n",
      "Epoch 15/50 | ‚è±Ô∏è  52.3s | üìâ Loss: 0.7620 | ‚úÖ Train:  72.7% | ‚≠ê Val:  71.7%\n",
      "Epoch 16/50 | ‚è±Ô∏è  55.1s | üìâ Loss: 0.7384 | ‚úÖ Train:  73.7% | ‚≠ê Val:  72.5%\n",
      "Epoch 17/50 | ‚è±Ô∏è  52.6s | üìâ Loss: 0.7185 | ‚úÖ Train:  74.5% | ‚≠ê Val:  74.2%\n",
      "Epoch 18/50 | ‚è±Ô∏è  52.8s | üìâ Loss: 0.7031 | ‚úÖ Train:  74.9% | ‚≠ê Val:  73.7%\n",
      "Epoch 19/50 | ‚è±Ô∏è  53.1s | üìâ Loss: 0.6881 | ‚úÖ Train:  75.5% | ‚≠ê Val:  74.4%\n",
      "Epoch 20/50 | ‚è±Ô∏è  54.1s | üìâ Loss: 0.6746 | ‚úÖ Train:  76.0% | ‚≠ê Val:  74.8%\n",
      "Epoch 21/50 | ‚è±Ô∏è  44.5s | üìâ Loss: 0.6608 | ‚úÖ Train:  76.5% | ‚≠ê Val:  74.2%\n",
      "Epoch 22/50 | ‚è±Ô∏è  48.1s | üìâ Loss: 0.6445 | ‚úÖ Train:  77.2% | ‚≠ê Val:  75.0%\n",
      "Epoch 23/50 | ‚è±Ô∏è  53.7s | üìâ Loss: 0.6346 | ‚úÖ Train:  77.4% | ‚≠ê Val:  76.0%\n",
      "Epoch 24/50 | ‚è±Ô∏è  53.1s | üìâ Loss: 0.6254 | ‚úÖ Train:  77.7% | ‚≠ê Val:  76.5%\n",
      "Epoch 25/50 | ‚è±Ô∏è  51.9s | üìâ Loss: 0.6148 | ‚úÖ Train:  78.2% | ‚≠ê Val:  76.2%\n",
      "Epoch 26/50 | ‚è±Ô∏è  52.6s | üìâ Loss: 0.6068 | ‚úÖ Train:  78.3% | ‚≠ê Val:  74.7%\n",
      "Epoch 27/50 | ‚è±Ô∏è  53.9s | üìâ Loss: 0.5973 | ‚úÖ Train:  78.5% | ‚≠ê Val:  75.0%\n",
      "Epoch 28/50 | ‚è±Ô∏è  52.9s | üìâ Loss: 0.5908 | ‚úÖ Train:  79.1% | ‚≠ê Val:  76.2%\n",
      "Epoch 29/50 | ‚è±Ô∏è  53.6s | üìâ Loss: 0.5809 | ‚úÖ Train:  79.3% | ‚≠ê Val:  76.1%\n",
      "Epoch 30/50 | ‚è±Ô∏è  52.9s | üìâ Loss: 0.5696 | ‚úÖ Train:  79.9% | ‚≠ê Val:  76.1%\n",
      "Epoch 31/50 | ‚è±Ô∏è  52.7s | üìâ Loss: 0.5659 | ‚úÖ Train:  79.9% | ‚≠ê Val:  76.6%\n",
      "Epoch 32/50 | ‚è±Ô∏è  34.2s | üìâ Loss: 0.5553 | ‚úÖ Train:  80.3% | ‚≠ê Val:  76.9%\n",
      "Epoch 33/50 | ‚è±Ô∏è  54.8s | üìâ Loss: 0.5495 | ‚úÖ Train:  80.6% | ‚≠ê Val:  76.6%\n",
      "Epoch 34/50 | ‚è±Ô∏è  55.8s | üìâ Loss: 0.5451 | ‚úÖ Train:  80.6% | ‚≠ê Val:  77.0%\n",
      "Epoch 35/50 | ‚è±Ô∏è  53.7s | üìâ Loss: 0.5388 | ‚úÖ Train:  80.7% | ‚≠ê Val:  76.5%\n",
      "Epoch 36/50 | ‚è±Ô∏è  53.5s | üìâ Loss: 0.5343 | ‚úÖ Train:  81.0% | ‚≠ê Val:  77.7%\n",
      "Epoch 37/50 | ‚è±Ô∏è  52.5s | üìâ Loss: 0.5271 | ‚úÖ Train:  81.2% | ‚≠ê Val:  77.7%\n",
      "Epoch 38/50 | ‚è±Ô∏è  52.8s | üìâ Loss: 0.5232 | ‚úÖ Train:  81.3% | ‚≠ê Val:  76.4%\n",
      "Epoch 39/50 | ‚è±Ô∏è  52.7s | üìâ Loss: 0.5195 | ‚úÖ Train:  81.5% | ‚≠ê Val:  77.5%\n",
      "Epoch 40/50 | ‚è±Ô∏è  52.9s | üìâ Loss: 0.5150 | ‚úÖ Train:  81.7% | ‚≠ê Val:  76.3%\n",
      "Epoch 41/50 | ‚è±Ô∏è  51.0s | üìâ Loss: 0.5139 | ‚úÖ Train:  81.8% | ‚≠ê Val:  78.3%\n",
      "Epoch 42/50 | ‚è±Ô∏è  47.2s | üìâ Loss: 0.5028 | ‚úÖ Train:  82.2% | ‚≠ê Val:  77.3%\n",
      "Epoch 43/50 | ‚è±Ô∏è  52.3s | üìâ Loss: 0.4961 | ‚úÖ Train:  82.4% | ‚≠ê Val:  78.0%\n",
      "Epoch 44/50 | ‚è±Ô∏è  52.8s | üìâ Loss: 0.4932 | ‚úÖ Train:  82.4% | ‚≠ê Val:  78.0%\n",
      "Epoch 45/50 | ‚è±Ô∏è  53.0s | üìâ Loss: 0.4886 | ‚úÖ Train:  82.6% | ‚≠ê Val:  78.3%\n",
      "Epoch 46/50 | ‚è±Ô∏è  52.6s | üìâ Loss: 0.4892 | ‚úÖ Train:  82.5% | ‚≠ê Val:  76.5%\n",
      "Epoch 47/50 | ‚è±Ô∏è  61.0s | üìâ Loss: 0.4827 | ‚úÖ Train:  82.9% | ‚≠ê Val:  79.0%\n",
      "Epoch 48/50 | ‚è±Ô∏è  59.0s | üìâ Loss: 0.4759 | ‚úÖ Train:  83.1% | ‚≠ê Val:  78.0%\n",
      "Epoch 49/50 | ‚è±Ô∏è  29.9s | üìâ Loss: 0.4760 | ‚úÖ Train:  83.0% | ‚≠ê Val:  77.1%\n",
      "Epoch 50/50 | ‚è±Ô∏è  53.5s | üìâ Loss: 0.4691 | ‚úÖ Train:  83.3% | ‚≠ê Val:  78.3%\n",
      "\n",
      "üíæ Model saved to 'model_final.pt'\n",
      "üìÑ Report saved to 'report.txt'\n",
      "‚úÖ Demo Complete!\n"
     ]
    }
   ],
   "source": [
    "# --- User Settings ---\n",
    "MODE = 'full'  # 'demo' (30mins, fast) or 'full' (90mins, better acc)\n",
    "TIME_BUDGET_MIN = 30\n",
    "FORCE_CPU = False\n",
    "# ---------------------\n",
    "\n",
    "config = Config(mode=MODE, time_budget_min=TIME_BUDGET_MIN, force_cpu=FORCE_CPU)\n",
    "print(f\"üöÄ Starting Main Loop with Budget: {TIME_BUDGET_MIN} mins\")\n",
    "\n",
    "# OOM Retry Loop\n",
    "while True:\n",
    "    try:\n",
    "        # Clean up memory\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        print(f\"\\n----------------------------------------------------------------\")\n",
    "        print(f\"‚ñ∂Ô∏è Attempting Config: {config}\")\n",
    "        print(f\"----------------------------------------------------------------\")\n",
    "        \n",
    "        trainloader, testloader, trainset, testset = get_dataloaders(config, subsample=(MODE == 'demo'))\n",
    "        \n",
    "        model = MiniViT(config).to(config.device)\n",
    "        params = model.count_params()\n",
    "        print(f\"üß† Model Parameters: {params:,}\")\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "        scaler = torch.cuda.amp.GradScaler(enabled=(config.device == 'cuda'))\n",
    "        \n",
    "        # --- Warmup Phase ---\n",
    "        start_time = time.perf_counter()\n",
    "        print(\"\\nüî• Running warmup epoch to measure speed...\")\n",
    "        train_loss, train_acc = train_one_epoch(model, trainloader, criterion, optimizer, scaler, config.device)\n",
    "        epoch_time = time.perf_counter() - start_time\n",
    "        print(f\"   Warmup done in {epoch_time:.2f}s.\")\n",
    "        \n",
    "        # --- Time Budgeting ---\n",
    "        total_time_needed = epoch_time * config.epochs\n",
    "        if total_time_needed > config.time_budget:\n",
    "            new_epochs = max(int(config.time_budget / epoch_time), 1)\n",
    "            print(f\"‚ö†Ô∏è Projected time {total_time_needed/60:.1f}m > budget {config.time_budget/60}m.\")\n",
    "            print(f\"   Adjusting epochs: {config.epochs} -> {new_epochs}\")\n",
    "            config.epochs = new_epochs\n",
    "\n",
    "        # --- Training Phase ---\n",
    "        print(f\"\\nüèãÔ∏è Starting training for {config.epochs} epochs...\")\n",
    "        history = []\n",
    "        total_start_time = time.time()\n",
    "        \n",
    "        for epoch in range(1, config.epochs + 1):\n",
    "            ep_start = time.perf_counter()\n",
    "            loss, acc = train_one_epoch(model, trainloader, criterion, optimizer, scaler, config.device)\n",
    "            val_acc = evaluate(model, testloader, config.device)\n",
    "            ep_duration = time.perf_counter() - ep_start\n",
    "            \n",
    "            print(f\"Epoch {epoch:02d}/{config.epochs} | ‚è±Ô∏è {ep_duration:5.1f}s | üìâ Loss: {loss:.4f} | ‚úÖ Train: {acc:5.1f}% | ‚≠ê Val: {val_acc:5.1f}%\")\n",
    "            history.append((epoch, loss, acc, val_acc))\n",
    "            \n",
    "        total_wall_time = time.time() - total_start_time\n",
    "        \n",
    "        # --- Save Phase (Auto) ---\n",
    "        torch.save(model.state_dict(), 'model_final.pt')\n",
    "        print(f\"\\nüíæ Model saved to 'model_final.pt'\")\n",
    "        \n",
    "        # --- Report Generation ---\n",
    "        report_content = (\n",
    "            f\"Mini-ViT Notebook Report\\n\"\n",
    "            f\"========================\\n\"\n",
    "            f\"Config: {config}\\n\"\n",
    "            f\"Params: {params:,}\\n\"\n",
    "            f\"Total Time: {total_wall_time:.1f}s\\n\"\n",
    "            f\"Avg Sec/Epoch: {total_wall_time/config.epochs:.2f}s\\n\"\n",
    "            f\"Final Val Acc: {history[-1][3]:.2f}%\\n\"\n",
    "            f\"Final Train Loss: {history[-1][1]:.4f}\\n\"\n",
    "            f\"Fallback Triggered: {config.fallback_level > 0}\\n\"\n",
    "        )\n",
    "        with open(\"report.txt\", \"w\") as f:\n",
    "            f.write(report_content)\n",
    "        print(\"üìÑ Report saved to 'report.txt'\")\n",
    "        print(\"‚úÖ Demo Complete!\")\n",
    "        break # Exit retry loop on success\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        if 'out of memory' in str(e):\n",
    "            print(\"\\nüö® CUDA OOM caught! Scaling down configuration...\")\n",
    "            if not config.downgrade():\n",
    "                print(\"‚ùå Could not downgrade further. Aborting.\")\n",
    "                raise e\n",
    "        else:\n",
    "            raise e\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
